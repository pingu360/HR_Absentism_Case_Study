{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "933569b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# import all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# create the special class that we are going to use from here on to predict new data\n",
    "class absenteeism_model():\n",
    "      \n",
    "        def __init__(self, model_file, scaler_file):\n",
    "            # read the 'model' and 'scaler' files which were saved\n",
    "            with open('model','rb') as model_file, open('scaler', 'rb') as scaler_file:\n",
    "                self.logreg_simplified = pickle.load(model_file)\n",
    "                self.scaler = pickle.load(scaler_file)\n",
    "                self.data = None\n",
    "        \n",
    "        # take a data file (*.csv) and preprocess it in the same way as in the lectures\n",
    "        def load_and_clean_data(self, data_file):\n",
    "            \n",
    "            # Group the reasons\n",
    "            df = pd.read_csv(data_file,delimiter=',')\n",
    "            bins = [1, 14, 17, 21, 28]\n",
    "            labels = ['1', '2', '3', '4']\n",
    "            df['Reason'] = pd.cut(df['Reason for Absence'], bins=bins, labels=labels, include_lowest=True)\n",
    "            df = df.drop(labels = ['Reason for Absence', 'ID'], axis = 1)\n",
    "            \n",
    "            # Convert the Date\n",
    "            df['Date'] = pd.to_datetime(df['Date'] , format='%d/%m/%Y')\n",
    "            df['Date'] = df['Date'].dt.strftime('%Y/%m/%d')\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df['Month Value'] = df['Date'].dt.month\n",
    "            df['Day of the Week'] = df['Date'].dt.dayofweek\n",
    "            df = df.drop(labels = 'Date', axis = 1)\n",
    "            \n",
    "            # Define the mapping dictionary\n",
    "            mapping = {1: 0, 2: 1, 3: 1, 4: 1}\n",
    "            # Method 1: Using map() function\n",
    "            df['Education'] = df['Education'].map(mapping)\n",
    "            \n",
    "            #Reorder columns\n",
    "            columns = [\n",
    "            'Reason',\n",
    "            'Month Value',\n",
    "            'Day of the Week',\n",
    "            'Transportation Expense',\n",
    "            'Distance to Work',\n",
    "            'Age',\n",
    "            'Daily Work Load Average',\n",
    "            'Body Mass Index',\n",
    "            'Education',\n",
    "            'Children',\n",
    "            'Pets',\n",
    "            'Absenteeism Time in Hours',\n",
    "            ]\n",
    "            \n",
    "            # Create dummy variables for the \"Category\" column\n",
    "            dummy_variables = pd.get_dummies(df['Reason'], prefix='Reason')\n",
    "            # Concatenate the dummy variables with the original DataFrame\n",
    "            df = pd.concat([dummy_variables ,df], axis=1)\n",
    "            # Drop the Reason column\n",
    "            df = df.drop('Reason',axis = 1)\n",
    "            self.preprocessed_data = df.copy()\n",
    "            \n",
    "            # In ML model file,we create a new scaler to deal with this problem\n",
    "            columns_to_scale = ['Transportation Expense','Age','Children','Pets']\n",
    "            df[columns_to_scale] = self.scaler.transform(df[columns_to_scale])\n",
    "            \n",
    "            columns_to_drop = ['Body Mass Index', 'Month Value',\n",
    "                   'Daily Work Load Average', 'Distance to Work', 'Education',\n",
    "                   'Day of the Week']\n",
    "            \n",
    "            df = df.drop(labels = columns_to_drop ,axis = 1)\n",
    "            self.data = df\n",
    "            \n",
    "\n",
    "            \n",
    "        # a function which outputs the probability of a data point to be 1\n",
    "        def predicted_probability(self):\n",
    "            if (self.data is not None):  \n",
    "                pred = self.logreg_simplified.predict_proba(self.data)[:,1]\n",
    "                return pred\n",
    "        \n",
    "        # a function which outputs 0 or 1 based on our model\n",
    "        def predicted_output_category(self):\n",
    "            if (self.data is not None):\n",
    "                pred_outputs = self.logreg_simplified.predict(self.data)\n",
    "                return pred_outputs\n",
    "        \n",
    "        # predict the outputs and the probabilities and \n",
    "        # add columns with these values at the end of the new data\n",
    "        def predicted_outputs(self):\n",
    "            if (self.data is not None):\n",
    "                self.preprocessed_data['Probability'] = self.logreg_simplified.predict_proba(self.data)[:,1]\n",
    "                self.preprocessed_data ['Prediction'] = self.logreg_simplified.predict(self.data)\n",
    "                return self.preprocessed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306ad140",
   "metadata": {},
   "source": [
    "## Reviews\n",
    "- 在原來ML model 中，我們定義了尚未進行變數篩選的Scaler\n",
    "- 進過Model improvement 的過程，我們篩選出想要的類別變數以及數值變數\n",
    "- 此時我們需要新的Scaler來幫助我們進行變數Scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
